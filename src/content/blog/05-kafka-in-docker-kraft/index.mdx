---
title: "Running Kafka Locally with Docker and KRaft Mode"
description: "Learn how to set up and run Apache Kafka locally using Docker with the new KRaft mode, eliminating the need for Zookeeper."
date: "2025-01-27"
tags:
  - "kafka"
  - "docker"
  - "kraft"
  - "streaming"
  - "message-queue"
  - "apache-kafka"
  - "kafka-docker"
  - "kafka-kraft-mode"
  - "kafka-without-zookeeper"
  - "local-kafka-setup"
  - "docker-compose-kafka"
  - "kafka-streaming-platform"
  - "kafka-cluster-docker"
  - "kafka-development-environment"
  - "kafka-local-development"
  - "kafka-docker-compose"
  - "kafka-kraft-configuration"
  - "kafka-broker-setup"
  - "kafka-docker-tutorial"
  - "kafka-kraft-cluster"
  - "kafka-docker-configuration"
  - "kafka-local-cluster"
  - "kafka-docker-setup"
  - "kafka-kraft-mode-tutorial"
  - "kafka-with-docker"
  - "kafka-local-development-setup"
  - "kafka-kraft-mode-docker"
  - "kafka-docker-cluster"
  - "kafka-kraft-mode-configuration"
ogImage: "/images/kafka-docker-kraft.png"
---

import { Picture } from "astro:assets";
import OgImage from "./kafka-docker-kraft.png";
import Callout from "@/components/Callout.astro";

---

<Picture
  src={OgImage}
  alt="Running Kafka Locally with Docker and KRaft Mode"
  inferSize
  formats={["avif", "webp"]}
/>

## Introduction

Apache Kafka is a distributed streaming platform that has become essential for building real-time data pipelines and streaming applications. Traditionally, Kafka relied on Zookeeper for cluster coordination, but with the introduction of KRaft (Kafka Raft Metadata) mode, Kafka can now operate without Zookeeper, simplifying deployment and management.

In this tutorial, we'll set up a local Kafka cluster using Docker and KRaft mode. This setup is perfect for development and testing purposes, allowing you to experiment with Kafka's features without the overhead of a full production setup.

## Prerequisites

Before we begin, ensure you have the following installed:

- Docker (version 20.10.0 or later)
- Docker Compose (version 1.29.0 or later)
- Basic understanding of Kafka concepts

## Setting Up the Docker Compose File

Create a `docker-compose.yml` file with the following configuration:

```yaml
version: '3.8'

services:
  kafka1:
    image: bitnami/kafka:3.7
    container_name: kafka1
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    volumes:
      - kafka_data:/bitnami/kafka

  kafka2:
    image: bitnami/kafka:3.7
    container_name: kafka2
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=2
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    depends_on:
      - kafka1
    volumes:
      - kafka_data:/bitnami/kafka

volumes:
  kafka_data:
```

This configuration sets up a two-node Kafka cluster in KRaft mode. Let's break down the key components:

1. **KAFKA_ENABLE_KRAFT=yes**: Enables KRaft mode
2. **KAFKA_CFG_NODE_ID**: Unique identifier for each node
3. **KAFKA_CFG_PROCESS_ROLES**: Specifies the node's roles (controller and broker)
4. **KAFKA_CFG_CONTROLLER_QUORUM_VOTERS**: Defines the voting members of the controller quorum
5. **KAFKA_CFG_LISTENERS**: Configures the network interfaces Kafka listens on
6. **KAFKA_CFG_ADVERTISED_LISTENERS**: Specifies the addresses clients should use to connect

## Starting the Kafka Cluster

To start the Kafka cluster, run:

```bash
docker-compose up -d
```

This command will start both Kafka nodes in detached mode. You can verify the containers are running with:

```bash
docker ps
```

## Creating a Topic

Once the cluster is running, let's create a test topic:

```bash
docker exec -it kafka1 kafka-topics.sh --create \
  --topic test-topic \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 2
```

This creates a topic named "test-topic" with 3 partitions and a replication factor of 2.

## Producing and Consuming Messages

Let's test our Kafka setup by producing and consuming messages:

1. Start a console producer:

```bash
docker exec -it kafka1 kafka-console-producer.sh \
  --topic test-topic \
  --bootstrap-server localhost:9092
```

2. In another terminal, start a console consumer:

```bash
docker exec -it kafka1 kafka-console-consumer.sh \
  --topic test-topic \
  --bootstrap-server localhost:9092 \
  --from-beginning
```

Now, any messages you type in the producer terminal should appear in the consumer terminal.

## Monitoring and Management

For monitoring your Kafka cluster, you can use Kafka's built-in tools or third-party solutions. Here's how to use Kafka's built-in tools:

1. List topics:

```bash
docker exec -it kafka1 kafka-topics.sh --list --bootstrap-server localhost:9092
```

2. Describe topic details:

```bash
docker exec -it kafka1 kafka-topics.sh --describe --topic test-topic --bootstrap-server localhost:9092
```

## Stopping the Cluster

When you're done, you can stop and remove the cluster with:

```bash
docker-compose down
```

This will stop the containers and remove the network, but preserve the Kafka data volume.

## Conclusion

Setting up Kafka locally with Docker and KRaft mode provides a lightweight, Zookeeper-free environment for development and testing. This setup is particularly useful for:

- Learning Kafka concepts
- Developing and testing Kafka applications
- Experimenting with Kafka configurations
- Building proof-of-concept projects

Remember that this setup is not suitable for production use. For production environments, you'll need to consider additional factors like security, monitoring, and proper cluster sizing.

<Callout type="info">
  I'm looking for a job, if you are looking for a senior backend developer,
  please consider me, I'm available on my email{" "}
  <a href="mailto:admin@saybackend.com">admin@saybackend.com</a>
</Callout>
